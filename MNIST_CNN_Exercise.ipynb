{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST-CNN - Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhPCqfT4rT97",
        "colab_type": "text"
      },
      "source": [
        "### MNIST with Tensorflow ###\n",
        "\n",
        "This is a tutorial to classify the MNIST images. The MNIST dataset is one of the most common dataset for image classification problem. We will be working on the problem of trying to recognize the actual digit from the handwritten representation. \n",
        "This dataset contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students.  We will use tensorFlow v1.15 for this tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzgIPPFRzaJn",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2019/02/Plot-of-a-Subset-of-Images-from-the-MNIST-Dataset.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-llY9tkYjLRj",
        "colab_type": "text"
      },
      "source": [
        "**Import the libraries**\n",
        "\n",
        "Let us start by importing the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csaj4ZQfl7uu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPu8xWhHNw-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "\n",
        "# Read data\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23Q-MUyRsJrc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zdjWzQocbu2z",
        "colab_type": "text"
      },
      "source": [
        "### Load the dataset ###\n",
        "\n",
        "To load the MNIST dataset, use the Keras.dataset API. This loads the dataset locally into the python variables.\n",
        "\n",
        "train_images and train_labels are arrays of training data - model uses to learn.\n",
        "\n",
        "test_images and test_labels are arrays of testing data - unseen data to test performance of the model.\n",
        "\n",
        "The first dimension in the train_images are the number of training examples. The next two dimensions are the size of the image which is 28 X 28.\n",
        "\n",
        "Similarly, the train_labels are the scalar labels for the 60,000 training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ln81l2MFb5p8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGqnCbUjgwUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Shape of training data: \", train_images.shape)\n",
        "print(\"Shape of training labels: \", train_labels.shape)\n",
        "print(\"Shape of testing data: \", test_images.shape)\n",
        "print(\"Shape of testing labels: \", test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QU2HhukdqE_",
        "colab_type": "text"
      },
      "source": [
        "**Visualize the dataset**\n",
        "\n",
        "To visualize the data, we use function imshow from matplolib libarary. Our image is a grayscale image of size 28 X 28.\n",
        "\n",
        "Note: A grayscale image is an image with single channel representing the intensity value. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhbybH52eV1h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "i=10\n",
        "\n",
        "plt.figure()\n",
        "# display images from the dataset\n",
        "lbl = train_labels[i]\n",
        "plt.imshow(train_images[i], cmap='gray')\n",
        "plt.title(\"Label: \"+ str(lbl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVTotWr8w8-T",
        "colab_type": "text"
      },
      "source": [
        "### Examine the dataset ###\n",
        "\n",
        "1. Basic check - There are no NANs in the input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH_IeIaJxDaS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.isnan(train_images).any())\n",
        "print(np.isnan(test_images).any())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNKwnibvdqqg",
        "colab_type": "text"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "**1. Normalize the image pixels**\n",
        "\n",
        "Inspect the image pixels before feeding them to the network. It is good practice to normalize the pixel values such that each pixel value has a value between 0 and 1. To do so, we normally divide the pixels simply by 255.\n",
        "\n",
        "Please note that we need to perform the same operation to both the training and testing dataset.\n",
        "\n",
        "**2. Reshape the images**\n",
        "\n",
        "Reshape the images before feeding them to the network.\n",
        "\n",
        "**3. One hot encode Labels:**\n",
        "\n",
        "A one-hot encoding is the representation of categorical variables as binary variables. Each integer value is represented by a binary vector which is all zeros except for the index of the integer, which is marked with a 1. For example- label 7 is represented as [0, 0, 0, 0, 0, 0, 0, 1, 0, 0].\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKB_9pFFdp3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.min(train_images[0]), \"\\t\", np.max(train_images[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWxtperRFuJA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images/255.\n",
        "test_images = test_images/255.\n",
        "print(np.min(train_images[0]), \"\\t\", np.max(train_images[0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58TpYzcAx6og",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape the images to feed it to the network\n",
        "train_images = train_images.reshape((-1, 28, 28, 1))\n",
        "test_images = test_images.reshape((-1, 28, 28, 1))\n",
        "print(train_images[0].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPTboj0X0Idx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = tf.keras.utils.to_categorical(train_labels, 10)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, 10)\n",
        "print(train_labels[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6SYZhKTmbJP",
        "colab_type": "text"
      },
      "source": [
        "### Defining Hyperparameters ###\n",
        "\n",
        "Hyperparameters are the non-trainable parameters in the system and are external to the system. They are important as they directly control the training algorithm and have an impact on the model being trained. Therefore, it is important to train our model with the right values of hyperparameters. \n",
        "\n",
        "**Learning rate:** Also referred to as the step size. This is one of the key hyperparameters to set in order to train a neural network. If the learning rate is too low, it may take a long time to converge or it may get stuck on a local plateau region. If the learning rate is set too high, the weight updates will be too large and the performance of the model will oscillate while training. \n",
        "\n",
        "**Training epochs:** Epoch is one cycle where the learner has seen the entire training dataset once. We initially set the training epochs to some high value and decide to terminate our model based on the training. As long as the error keeps dropping on our validation dataset, we continue the training. If the validation error starts increasing, this could be because of overfitting. So we terminate our model training early to prevent our model from overfitting on the training data.\n",
        "\n",
        "**Batch size:** The Batch size defines how many examples will be propogated from the network at once. For example, if you have 500 training examples and we choose a batch size of 100. The algorithm randomly choses 100 examples from the entire dataset and trains the network. Next, it takes another 100 examples and trains the network again. This continues until the model has seen all the examples from the training dataset.\n",
        "\n",
        "*   It is important if you are not able to fit the entire dataset into the memory. Training with a smaller batch size requires less memory. \n",
        "*   Model trains faster in batches. This is because we update the network parameters after each iteration (training on one batch).\n",
        "\n",
        "In general, batch size of 32 is a good starting point, and you should also try with 64, 128, and 256. It is recommended to use a batch size in the power of 2, since the number of physical processor is often a power of 2.\n",
        "Make sure that your machine has sufficient RAM to handle the specific batch size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvPtMOiPmUoY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "steps_num = 15\n",
        "learning_rate = 0.001 \n",
        "batch_size = 128 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDSTRkHziLPv",
        "colab_type": "text"
      },
      "source": [
        "### Network parameters ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEkbUFZiMx4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image_size= 28 \n",
        "labels_size = 10 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHD9BaClmzG3",
        "colab_type": "text"
      },
      "source": [
        "**Setup the architecture**\n",
        "\n",
        "Tensors can be stored in the graph as constants or variables. As you might guess, constants hold tensors whose values can't change, while variables hold tensors whose values can change. \n",
        "\n",
        "**Constant:** same as in programming.\n",
        "If we assign data object a value, it does not change.\n",
        "\n",
        "**Placeholder:** A graph can be parameterized to accept external inputs, known as placeholders. A promise to provide the values later. Placeholders will be filled with the values passed when evaluating the computational graph.\n",
        "\n",
        "**Variable:** To add trainable parameters to the graph\n",
        "Use tf.global_variables_initializer() in tensorflow to initialize all variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDqLF5V8mvpD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# defining placeholders\n",
        "training_data = tf.placeholder(tf.float32, [None, image_size, image_size, 1]) # input placeholder\n",
        "labels = tf.placeholder(tf.float32, [None, labels_size]) # output data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqlhLJAum3GN",
        "colab_type": "text"
      },
      "source": [
        "The first dimension is None. It tells the placeholder that it will receive this dimension when you feed in the data to it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AX9L1VaIkKek",
        "colab_type": "text"
      },
      "source": [
        "# Exercise 2 - Wrapper functions\n",
        "\n",
        "Use the below hints to design the wrapper functions.\n",
        "\n",
        "1. **tf.nn.conv2d** - https://www.tensorflow.org/api_docs/python/tf/nn/conv2d\n",
        "\n",
        "    Hint - tf.nn.conv2d(input, filter_weights, strides=[1, s, s, 1], padding='SAME/VALID') \n",
        "\n",
        "    strides - the first and last dimension is always 1. First dimension is the image number and the last dimension is for the input channel.\n",
        "      \n",
        "    padding - Let us use the padding type as 'SAME' to keep the image dimensions as same.\n",
        "\n",
        "2. **tf.nn.bias_add** - https://www.tensorflow.org/api_docs/python/tf/nn/bias_add\n",
        "\n",
        "    Hint - tf.nn.bias_add(input, bias)\n",
        "\n",
        "\n",
        "3. **tf.nn.relu** - https://www.tensorflow.org/api_docs/python/tf/nn/relu\n",
        "\n",
        "    Hint - tf.nn.relu(y)\n",
        "\n",
        "\n",
        "4. **tf.nn.max_pool** - https://www.tensorflow.org/api_docs/python/tf/nn/max_pool\n",
        "\n",
        "    Hint - tf.nn.max_pool(input, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding='SAME/VALID')\n",
        "\n",
        "    In case of max pooling, using the same padding, we take into account the border pixels. The size of the output depends on the stride rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkEglMGoiCmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convolution layer + Relu\n",
        "def conv2d(x, W, b, s):\n",
        "  '''\n",
        "    x - input image\n",
        "    W - Filter for convolution\n",
        "    b - bias term\n",
        "    s - stride rate\n",
        "  '''\n",
        "  # Define a convolution layer\n",
        "  y = tf.nn.conv2d(x, W, strides=[1, s, s, 1], padding='SAME') \n",
        "\n",
        "  # Add bias\n",
        "  y = tf.nn.bias_add(y, b)\n",
        "  \n",
        "  # Apply non-linear activation (bias activation)\n",
        "  # Fill here.\n",
        "  \n",
        "  # Return the result\n",
        "  return y\n",
        "\n",
        "# Max pooling layer\n",
        "def maxpool2d(x, k):\n",
        "  '''\n",
        "    x - input image\n",
        "    k - kernel(or filter) size\n",
        "  '''\n",
        "  # Define a max pooling layer\n",
        "  # Fill here\n",
        "\n",
        "  # Return the result\n",
        "  return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6r6eXagkqlTV",
        "colab_type": "text"
      },
      "source": [
        "**Weight and Bias Parameters**\n",
        "\n",
        "#### For conv layers: ####\n",
        "\n",
        "A **weight variable** will be of the form: **(f, f, c, out_c)** - You apply out_c number of filters of size f X f across c channels.\n",
        "\n",
        "The first and second parameter are the filter size, third parameter is the input number of channels, fourth parameter is the output number of channel of the layer.\n",
        "\n",
        "\n",
        "#### For fully connected layers: ####\n",
        "\n",
        "Since we will flatten the image before feeding into the fully connected layers. The weights of the FC layers are of the form - **(input_dim, output_dim)**\n",
        "\n",
        "\n",
        "A **bias variable** shape is equivalent to the number of output channels of that layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMyEw2nWlZ-h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = {\n",
        "    'wc1' : tf.get_variable('W0', shape=(3, 3, 1, 32), initializer=tf.contrib.layers.xavier_initializer()), # here 3 is the filter size.\n",
        "    'wd1' : tf.get_variable('W3', shape=(14*14*32, 128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'wd2' : tf.get_variable('W4', shape=(128, 10), initializer=tf.contrib.layers.xavier_initializer())\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmFaiaDlujUa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "biases = {\n",
        "    'bc1' : tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bd1' : tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "    'bd2' : tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZ2Ye0CftaqL",
        "colab_type": "text"
      },
      "source": [
        "### Model Architecture ###\n",
        "\n",
        "There are multiple APIs to define a model in TensorFlow. We are using the Sequential model API to create a Convolutional Neural Network model with Convolution layer followed by pooling layer and dropout. At the end, we unfold the data into dense layers that outputs the logits for the 10 categories of data in Fashion MNIST."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsQdxWW1vJVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X, weights, biases):\n",
        "  # convolution block 1\n",
        "  conv1 = conv2d(X, weights['wc1'], biases['bc1'], 1)\n",
        "  conv1 = maxpool2d(conv1, k=2) # returns an output of shape 14 X 14\n",
        "  \n",
        "  # Fully connected layers\n",
        "  fc1 = tf.reshape(conv1, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
        "  fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
        "  fc1 = tf.nn.relu(fc1)\n",
        "  \n",
        "  # Final layer\n",
        "  output = tf.add(tf.matmul(fc1, weights['wd2']), biases['bd2'])\n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQiz8MMH0RdC",
        "colab_type": "text"
      },
      "source": [
        "If your targets are one-hot encoded, use cross entropy loss function.\n",
        "Read more about this loss function [here](https://www.tensorflow.org/api_docs/python/tf/nn/softmax_cross_entropy_with_logits).\n",
        "\n",
        "To learn more about the Adam optimizer, look [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgJp-AxFxY_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model(training_data, weights, biases)\n",
        "\n",
        "# tf.reduce_mean calculates the mean over all the batches to get the single loss value.\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=predict, labels=labels))\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8Z9xemn3WYi",
        "colab_type": "text"
      },
      "source": [
        " Evaluating the model predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8h9wCRl1Q14",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = tf.argmax(predict, 1)\n",
        "gt = tf.argmax(labels, 1)\n",
        "\n",
        "correct_pred = tf.equal(prediction, gt)\n",
        "\n",
        "# calculate the accuracy across the images and average them out.\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhKfCphP4CU4",
        "colab_type": "text"
      },
      "source": [
        "### Training the model ###\n",
        "\n",
        "**TensorFlow Graphs:**\n",
        "\n",
        "A Graph contains a set of tf.Operation objects, which represent units of computation; and tf.Tensor objects, which represent the units of data that flow between operations. Graphs must run within a TensorFlow session, which holds the state for the graph(s) it runs.\n",
        "\n",
        "To compute anything, a graph must be launched in a session. A session allows to execute the graph or part of a graphs. It allocates resources for that and holds the actual values of intermediate results and variables. Technically, session places the graph ops on hardware such as CPUs or GPUs and provides methods to execute them.\n",
        "\n",
        "\n",
        "**Initializing the global variables:**\n",
        "This creates a single node containing all the assign nodes of all the variables constructed so far, and associate it to the python variable 'init' so that when the line sess.run(init) is executed all the variables acquire their initial values.\n",
        "\n",
        "\n",
        "\n",
        "**Summary**\n",
        "\n",
        "TensorFlow programming is essentially a two-step process:\n",
        "1. Assemble constants, variables, and operations into a graph.\n",
        "2. Evaluate those constants, variables and operations within a session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzNJ5ryb4AYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# initialize the global variables\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# to save the variables\n",
        "saver = tf.train.Saver(max_to_keep=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKCUOj3OAxLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(init)\n",
        "  writer = tf.summary.FileWriter('./graphs1', sess.graph)\n",
        "  train_loss, test_loss, train_acc, test_acc = [], [], [], []\n",
        "  \n",
        "  for ep in range(steps_num):\n",
        "    train_loss_ep, train_acc_ep = [], []\n",
        "\n",
        "    num_iterations = len(train_images)//batch_size\n",
        "    for itr in range(num_iterations):\n",
        "      batch_x = train_images[itr*batch_size:min((itr+1)*batch_size, len(train_images))]\n",
        "      batch_y = train_labels[itr*batch_size:min((itr+1)*batch_size, len(train_images))]\n",
        "      \n",
        "      # run the optimizer, loss and accuracy      \n",
        "      _, loss_val, acc_val = sess.run([optimizer, loss, accuracy], feed_dict={training_data: batch_x, labels: batch_y})\n",
        "      assert(not np.isnan(loss_val))\n",
        "      \n",
        "      train_loss_ep.append(loss_val)\n",
        "      train_acc_ep.append(acc_val)\n",
        "      \n",
        "    # find the training loss and accuracy per epoch\n",
        "    train_loss_per_epoch = np.mean(np.array(train_loss_ep))\n",
        "    train_loss.append(train_loss_per_epoch)\n",
        "    train_acc_per_epoch = np.mean(np.array(train_acc_ep))\n",
        "    train_acc.append(train_acc_per_epoch)\n",
        "    \n",
        "    print(\"\\nEpoch: {:0d} \\t Training Loss: {:.3f}, Training Accuracy: {:.3f}\".format(ep, train_loss_per_epoch, train_acc_per_epoch))\n",
        "     \n",
        "    # find testing loss and accuracy \n",
        "    test_loss_ep, test_acc_ep = sess.run([loss, accuracy], feed_dict={training_data: test_images, labels: test_labels})\n",
        "    \n",
        "    print(\"\\nTesting Loss: {:.3f}, Testing Accuracy: {:.3f}\".format(test_loss_ep, test_acc_ep))\n",
        "    test_acc.append(test_acc_ep)\n",
        "    test_loss.append(test_loss_ep)\n",
        "\n",
        "    saver.save(sess, './model/model1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2D2ur7wPzQ43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the graph in tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir ./graphs1/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4wifUwo9OSEk",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the results ###"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxDQbpkEOU-d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  saver.restore(sess, './model/model1')\n",
        "  print(\"Restored parameters\")\n",
        "  out, actual = sess.run([prediction, gt], feed_dict={training_data: test_images, labels: test_labels})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BViKbhb3Yu_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "figure = plt.figure(figsize=(15, 15))\n",
        "for i, index in enumerate(np.random.choice(10000, size=9)):\n",
        "    sub = figure.add_subplot(3, 3, i + 1)\n",
        "    sub.imshow(np.squeeze(test_images[index]))\n",
        "    sub.set_title(\"{} (Actual Label: {})\".format(out[index], actual[index]), color=(\"green\" if out[index] == actual[index] else \"red\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXf9l5y8W-a-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the loss.\n",
        "plt.plot(range(len(train_loss)), train_loss, 'r', label=\"Training Loss\")\n",
        "plt.plot(range(len(test_loss)), test_loss, 'b', label=\"Testing Loss\")\n",
        "plt.title(\"Training vs Testing Loss\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A6MjVCoX6c7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize the accuracy.\n",
        "plt.plot(range(len(train_acc)), train_acc, 'r', label=\"Training Accuracy\")\n",
        "plt.plot(range(len(test_acc)), test_acc, 'b', label=\"Testing Accuracy\")\n",
        "plt.title(\"Training vs Testing Accuracy\")\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}